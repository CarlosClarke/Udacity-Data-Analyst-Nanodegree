{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle Report\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this project we're studying data from the **WeRateDogs** tweeter account that rates people's dogs with funny comments about the dogs. We will use Wrangling to tackle this task. \n",
    "The Wrangling steps are:\n",
    "- Gathering Data\n",
    "- Assessing Data\n",
    "- Cleaning Data\n",
    "\n",
    "### Gathering\n",
    "\n",
    "In this step we will gather all three datasets needed for the project. Each process of gathering the data will be different. \n",
    "- The **WeRateDogs** Twitter archive will come from a manual download by following link to <a href=\"https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a4e958_twitter-archive-enhanced/twitter-archive-enhanced.csv\" target=\"_blank\">twitter_archive_enhanced.csv</a> file.\n",
    "- The tweet image predictions file (**image_predictions.tsv**) is present in each tweet according to a neural network. The file is hosted on the Udacity servers and should be downloaded programmatically using the request library and following link (URL of the file: <a href=\"https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\" target=\"_blank\">https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv</a>)\n",
    "- Gather each tweet's retweet count and favorite (\"like\") count at the minimum and any additional data you find interesting. Using the tweet IDs in the **WeRateDogs Twitter archive**, query the **Twitter API** for each tweet's **JSON** data using Python's Tweepy library and store each tweet's entire set of JSON data in a file called **tweet_json.txt** file.\n",
    "- Import the data into our programming environment (**Jupyter Notebook**).\n",
    "\n",
    "### Assessing\n",
    "\n",
    "After gathering all three pieces of data, assess them visually and programmatically for quality and tidiness issues. Detect and document quality issues and tidiness issues.\n",
    "\n",
    "You need to use two types of assessment:\n",
    "\n",
    "**Visual assessment:** Display the data in the Jupyter Notebook for visual assessment purposes. \n",
    "\n",
    "**Programmatic assessment:** Use pandas' functions and/or methods to assess the data.\n",
    "\n",
    "### Quality issues (Completeness, Validity, Accuracy, Consistency)\n",
    "#### Tweeter Archives Dataset####\n",
    "- The following columns (*in_reply_to_status_id, in_reply_to_user_id,\n",
    "retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp*) are part of retweeting. The data metrics will eventually be removed for our data analysis. No retweet informaiton.\n",
    "\n",
    "- Data type for *timestamp* should be a datetime and not a string object.\n",
    "\n",
    "- The *doggo, floofer, pupper, puppo* state invalid values, i.e \"None\". Need to be converted to \"NaN\".\n",
    "\n",
    "- The following columns (*doggo, floofer, pupper, puppo*) are actual values for the dog types. They need to be included as values under the new \"Dog Stage\" column, as well as removed.\n",
    "\n",
    "- The *Name* columns state invalid values \"None\", replace with \"NaN\".\n",
    "\n",
    "- The *rating_numerator* equal to zero for the following records:\n",
    " - tweet_id: 835152434251116546 \n",
    " - tweei_id: 746906459439529985 \n",
    "\n",
    "- There *rating_denominator* equal to zero for the following record:\n",
    " - tweet_id: 835246439529840640; Note: This is a retweet so will be    removed during that process.\n",
    " \n",
    "- Create a new rating column from the numerator and denominator for rating standards. \n",
    "\n",
    "- Change the datatype for the rating_numerator and rating_denominator from int to float, in order for the decimals to show.\n",
    "\n",
    "- Remove all values in the Name column that have lower case letters, i.e. a, an, actually, the, etc.\n",
    "\n",
    "\n",
    "#### Image Prediction Dataset ####\n",
    "- The *p1, p2, p3* column names don't make senses and don't have descriptions. Need better column names with    capitalization.\n",
    "\n",
    "- Duplicate *jpg_url* for some tweet_id's. Need to be removed.\n",
    "\n",
    "- Removed the useless img_num column.\n",
    "\n",
    "- Lower and upper case letters for some values in prediction columns.\n",
    "\n",
    "- Data type for *tweet_id* should be a string object and not a int (number).\n",
    "\n",
    "\n",
    "#### Tweet (JSON) Dataset####\n",
    "- Rename the id column to match the other dataset column name of tweet_id.\n",
    "\n",
    "- Change the datatype of the tweet_id column to a string object from an int.\n",
    "\n",
    "- The majority of the columns aren't needed for the analysis. We'll remove the metrics.\n",
    "\n",
    "### Cleaning\n",
    "\n",
    "As part of the cleaning process we'll take care of all the issues documented while assessing. We will create and keep the necessary columns and others may be removed and dropped. The dataset will be cleaned and provide quality metrics.\n",
    "\n",
    "Make sure you complete the following items in this step.\n",
    "\n",
    "- Before you perform the cleaning, you will make a copy of the original data.\n",
    "- During cleaning, use the define-code-test framework and clearly document it.\n",
    "- Cleaning includes merging individual pieces of data according to the rules of tidy data. \n",
    "- The results should be a High-Quality and Master DataFrame.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Data wrangling is a core skill that everyone who works with data should be familiar with since so much of the world's data isn't clean. In this project we tackled all the concepts of the wrangling process from gathering, assessing, and cleaning the data. These are important steps to handling dirty and messy data to achieve high quality data analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
