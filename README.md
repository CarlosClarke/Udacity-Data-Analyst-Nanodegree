# Udacity - Data Analyst Nanodegree
Udacity's Data Analyst Nanodegree program outline and project files.

In January 2023, I commenced the Udacity Data Analyst Nanodegree program, and 
this repository encompasses the project files and notes associated with it.

## Program Outline
**Intro to Data Analysis**    
Project: Investigate a Dataset
* **Anaconda**  
This topic covers a brief overview of the Anaconda environment, widely recognized as one of the most popular environments for Python-based data analysis.
* **Jupyter Notebooks**  
Jupyter Notebooks serve as an excellent resource for initiating Python code writing. While in production scenarios, code is commonly crafted in scripts, notebooks prove invaluable for sharing insights and showcasing data visualizations.
* **The Data Analysis Process**  
Explore the data analysis process and enhance your skills in investigating diverse datasets by utilizing Python and its robust packages tailored for data analysis.
* **Programming Workflow for Data Analysis**  
Expand your knowledge by delving into an alternative workflow for Python analysis. This includes exploring IPython's command line interface, composing scripts in text editors, and executing scripts in the terminal.

**Practical Statistics**  
Project: Analyze A/B Test Results
* **Descriptive Statistics**  
This topic covers insights into data types, measures of central tendency, and the fundamentals of statistical notation. The following measures are examined: variability, distribution shape, and identifying outliers in the context of quantitative data.
* **Probability**  
Acquire the fundamentals of understanding probability.
* **Binomial Distribution**  
Exploring Binomial Distribution, a widely utilized probability distribution.
* **Conditional Probability**  
Not all events operate independently. Probability rules govern dependent events, as well.
* **Bayes Rule**  
Acquire knowledge of one of the paramount principles in statistics - Bayes' Rule.
* **Normal Distribution Theory**  
Understand the mathematical principles involved in transitioning from a simple coin-flip scenario to a normal distribution.
* **Sampling Distributions and the Central Limit Theorem**  
Delve into the fundamentals of confidence intervals and hypothesis testing by gaining a comprehensive understanding of the underlying concept: sampling distributions.
* **Confidence Intervals**  
Discover the application of sampling distributions and bootstrapping techniques to construct a confidence interval for any parameter of interest.
* **Hypothesis Testing**  
Acquire the essential skills for both constructing and analyzing results in hypothesis testing.
* **Regression**  
Leverage Python to implement linear regression models and gain proficiency in interpreting the outcomes of these models.
* **Multiple Linear Regression**  
Acquire the knowledge and skills to implement multiple linear regression models in Python. Gain proficiency in interpreting the results and assessing the goodness of fit for your model.
* **Logistic Regression**  
Develop expertise in utilizing logistic regression models in Python. Gain the ability to interpret the results and assess the goodness of fit for your logistic regression model.
 
**Data Modeling**  
Project: Data Modeling with Postgres
* **Intro to Data Modeling**  
This topic covers the fundamental distinctions between relational and non-relational databases. The lesson will elucidate how each database type aligns with the varied requirements of data consumers.
* **Relational Data Models**  
This topic provides insight into the significance of data modeling, exploring the advantages and limitations of relational databases, and active engagement in creating schemas and tables within the Postgres environment.

**Data Wrangling**  
Project: Wrangle and Analyze Data
* **Intro to Data Wrangling**  
Recognize each stage of the data wrangling process, encompassing gathering, assessing, and cleaning, by navigating through a concise walkthrough of the entire procedure.
* **Gathering Data**  
Collect data from diverse sources and an array of file formats using Python.
* **Assessing Data**  
Examine data for both quality and tidiness concerns through visual inspection and programmatically using pandas in Python.
* **Cleaning Data**  
Utilize pandas in Python to rectify the identified quality and tidiness issues during the data assessment phase.

**Data Visualization**  
Project: Build Data Dashboards
* **Data Visualization Fundamentals**  
This topic covers the skills to assess the quality of data visualizations and construct high-quality visuals. The foundational aspects of data dashboards are covered.
* **Design Principles**  
Theres' a need to apply optimal design practices and select the most suitable chart for specific situations, ensuring effective visualization implementation.
* **Creating Visualizations in Tableau**  
This topic goes through the process of constructing data visualizations in Tableau. The lesson covers the utilization of data hierarchies, filters, groups, sets, and calculated fields, along with the creation of map-based visualizations in Tableau.
* **Telling Stories with Tableau**  
Providing proficiencies in constructing interactive Tableau dashboards and mastering the art of narrating impactful stories through data visualization.

**R Programming (From Programming for Data Science)**  
Project: Explore Bikeshare Data - R
* **Intro to R**  
This topic explores the factors contributing to the widespread popularity of R in the realm of data analysis.
* **Syntax & Data Types**  
In this section, acquire a comprehensive understanding of interacting with the R interpreter and getting accustomed to the various data types accessible in R.
* **Control Flow & Functions**  
Cover fundamental programming concepts in the R syntax. Explore topics such as control flow, loops, and functions to build a strong foundation in programming with R.
* **Data Visualizations & EDA**  
Dive into the practical aspects of creating plots in R. Experience the power of R to craft impressive visualizations with just a few lines of code.

**Supervised Learning**  
Project: Finding Donors for CharityML
* **Machine Learning Bird’s Eye View**  
Before delving into the numerous machine learning algorithms, it's crucial to take a step back and comprehend the broader perspective encompassing the entire field.
* **Linear Regression**  
Linear regression stands as one of the fundamental algorithms in the realm of machine learning.
* **Perceptron Algorithm**  
The perceptron algorithm serves as a method for classifying data and forms the foundational building block of neural networks.
* **Decision Trees**  
Decision trees represent a framework for decision-making, wherein each decision leads to a set of consequences or prompts additional decisions.
* **Naïve Bayes**  
Naïve Bayesian Algorithms serve as powerful tools for constructing classifiers for labeled data. Notably, Naïve Bayes is commonly applied in scenarios involving text data and classification problems.
* **Support Vector Machines**  
Support vector machines are a prevalent method employed for addressing classification problems, and their effectiveness is notably demonstrated through the application of the "kernel trick."
* **Ensemble Methods**  
Bagging and boosting are two prevalent ensemble methods that involve combining simple algorithms to create more advanced models, surpassing the performance of individual algorithms on their own.
* **Model Evaluation Metrics**  
Acquire knowledge of the primary metrics used to evaluate models, including accuracy, precision, and recall.
* **Training and Tuning**  
Familiarize yourself with the main types of errors that can occur during training and explore various methods to address and optimize your machine learning models.

**Unsupervised Learning**  
Project: Creating Customer Segments with Arvato
* **Clustering**  
Clustering stands out as one of the most prevalent unsupervised learning methods, with K-means clustering being a notable algorithm within this category.
* **Hierarchical and Density Based Clustering**  
The exploration of clustering methods persists, focusing on hierarchical clustering and density-based clustering, notably DBSCAN.
* **Gaussian Mixture Models and Cluster Validation**  
This topic covers the Gaussian mixture model clustering, followed by an exploration of the cluster analysis process and methods for validating clustering results.
* **Dimensionality Reduction and PCA**  
Frequently, there is a need to condense many features in data to a more concise and pertinent set. Principal Component Analysis, or PCA, serves as a method for feature extraction and dimensionality reduction in such cases.
* **Random Projection and PCA**  
This topic covers two other methods for feature extraction and dimensionality reduction: Projection and Independent Component Analysis (ICA).
